Index: linux-3.4.11/include/linux/smp_lock.h
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ linux-3.4.11/include/linux/smp_lock.h	2016-04-22 15:28:19.304098027 +0800
@@ -0,0 +1,52 @@
+#ifndef __LINUX_SMPLOCK_H
+#define __LINUX_SMPLOCK_H
+
+#ifdef CONFIG_LOCK_KERNEL
+#include <linux/sched.h>
+
+#define kernel_locked()		(current->lock_depth >= 0)
+
+extern int __lockfunc __reacquire_kernel_lock(void);
+extern void __lockfunc __release_kernel_lock(void);
+
+/*
+ * Release/re-acquire global kernel lock for the scheduler
+ */
+#define release_kernel_lock(tsk) do { 		\
+	if (unlikely((tsk)->lock_depth >= 0))	\
+		__release_kernel_lock();	\
+} while (0)
+
+static inline int reacquire_kernel_lock(struct task_struct *task)
+{
+	if (unlikely(task->lock_depth >= 0))
+		return __reacquire_kernel_lock();
+	return 0;
+}
+
+extern void __lockfunc lock_kernel(void)	__acquires(kernel_lock);
+extern void __lockfunc unlock_kernel(void)	__releases(kernel_lock);
+
+/*
+ * Various legacy drivers don't really need the BKL in a specific
+ * function, but they *do* need to know that the BKL became available.
+ * This function just avoids wrapping a bunch of lock/unlock pairs
+ * around code which doesn't really need it.
+ */
+static inline void cycle_kernel_lock(void)
+{
+	lock_kernel();
+	unlock_kernel();
+}
+
+#else
+
+#define lock_kernel()				do { } while(0)
+#define unlock_kernel()				do { } while(0)
+#define release_kernel_lock(task)		do { } while(0)
+#define cycle_kernel_lock()			do { } while(0)
+#define reacquire_kernel_lock(task)		0
+#define kernel_locked()				1
+
+#endif /* CONFIG_LOCK_KERNEL */
+#endif /* __LINUX_SMPLOCK_H */
Index: linux-3.4.11/include/net/sock.h
===================================================================
--- linux-3.4.11.orig/include/net/sock.h	2016-04-22 15:21:43.394503122 +0800
+++ linux-3.4.11/include/net/sock.h	2016-04-22 15:28:19.304098027 +0800
@@ -1722,7 +1722,7 @@
 {
 	int err, offset = skb->len;
 
-	err = skb_do_copy_data_nocache(sk, skb, from, skb_put(skb, copy),
+	err = skb_do_copy_data_nocache(sk, skb, from,(char *) skb_put(skb, copy),
 				       copy, offset);
 	if (err)
 		__skb_trim(skb, offset);
